<class 'pytorch_lightning.loggers.tensorboard.TensorBoardLogger'>
Here is the list of contents
__module__
pytorch_lightning.loggers.tensorboard
__doc__

    Log to local file system in `TensorBoard <https://www.tensorflow.org/tensorboard>`_ format.

    Implemented using :class:`~torch.utils.tensorboard.SummaryWriter`. Logs are saved to
    ``os.path.join(save_dir, name, version)``. This is the default logger in Lightning, it comes
    preinstalled.

    Example:

    .. testcode::

        from pytorch_lightning import Trainer
        from pytorch_lightning.loggers import TensorBoardLogger

        logger = TensorBoardLogger("tb_logs", name="my_model")
        trainer = Trainer(logger=logger)

    Args:
        save_dir: Save directory
        name: Experiment name. Defaults to ``'default'``. If it is the empty string then no per-experiment
            subdirectory is used.
        version: Experiment version. If version is not specified the logger inspects the save
            directory for existing versions, then automatically assigns the next available version.
            If it is a string then it is used as the run-specific subdirectory name,
            otherwise ``'version_${version}'`` is used.
        log_graph: Adds the computational graph to tensorboard. This requires that
            the user has defined the `self.example_input_array` attribute in their
            model.
        default_hp_metric: Enables a placeholder metric with key `hp_metric` when `log_hyperparams` is
            called without a metric (otherwise calls to log_hyperparams without a metric are ignored).
        prefix: A string to put at the beginning of metric keys.
        sub_dir: Sub-directory to group TensorBoard logs. If a sub_dir argument is passed
            then logs are saved in ``/save_dir/version/sub_dir/``. Defaults to ``None`` in which
            logs are saved in ``/save_dir/version/``.
        \**kwargs: Additional arguments used by :class:`SummaryWriter` can be passed as keyword
            arguments in this logger. To automatically flush to disk, `max_queue` sets the size
            of the queue for pending logs before flushing. `flush_secs` determines how many seconds
            elapses before flushing.

    
NAME_HPARAMS_FILE
hparams.yaml
LOGGER_JOIN_CHAR
-
__init__
<function TensorBoardLogger.__init__ at 0x0000021BFC49F160>
root_dir
<property object at 0x0000021BFC4A0270>
log_dir
<property object at 0x0000021BFC4A0090>
save_dir
<property object at 0x0000021BFC4A02C0>
sub_dir
<property object at 0x0000021BFC4C3D10>
experiment
<property object at 0x0000021BFC5E0AE0>
log_hyperparams
<function TensorBoardLogger.log_hyperparams at 0x0000021BFCD8D5E0>
log_metrics
<function TensorBoardLogger.log_metrics at 0x0000021BFCD8D700>
log_graph
<function TensorBoardLogger.log_graph at 0x0000021BFCD8D820>
save
<function TensorBoardLogger.save at 0x0000021BFCD8D940>
finalize
<function TensorBoardLogger.finalize at 0x0000021BFCD8DA60>
name
<property object at 0x0000021BFCD8B090>
version
<property object at 0x0000021BFCD8B0E0>
_get_next_version
<function TensorBoardLogger._get_next_version at 0x0000021BFCD8DC10>
_sanitize_params
<staticmethod object at 0x0000021BFC49B760>
__getstate__
<function TensorBoardLogger.__getstate__ at 0x0000021BFCD8DD30>
__abstractmethods__
frozenset()
_abc_impl
<_abc._abc_data object at 0x0000021BFCD8E200>
<class 'pytorch_lightning.loggers.tensorboard.TensorBoardLogger'>
Here is the list of contents
__module__
pytorch_lightning.loggers.tensorboard
__doc__

    Log to local file system in `TensorBoard <https://www.tensorflow.org/tensorboard>`_ format.

    Implemented using :class:`~torch.utils.tensorboard.SummaryWriter`. Logs are saved to
    ``os.path.join(save_dir, name, version)``. This is the default logger in Lightning, it comes
    preinstalled.

    Example:

    .. testcode::

        from pytorch_lightning import Trainer
        from pytorch_lightning.loggers import TensorBoardLogger

        logger = TensorBoardLogger("tb_logs", name="my_model")
        trainer = Trainer(logger=logger)

    Args:
        save_dir: Save directory
        name: Experiment name. Defaults to ``'default'``. If it is the empty string then no per-experiment
            subdirectory is used.
        version: Experiment version. If version is not specified the logger inspects the save
            directory for existing versions, then automatically assigns the next available version.
            If it is a string then it is used as the run-specific subdirectory name,
            otherwise ``'version_${version}'`` is used.
        log_graph: Adds the computational graph to tensorboard. This requires that
            the user has defined the `self.example_input_array` attribute in their
            model.
        default_hp_metric: Enables a placeholder metric with key `hp_metric` when `log_hyperparams` is
            called without a metric (otherwise calls to log_hyperparams without a metric are ignored).
        prefix: A string to put at the beginning of metric keys.
        sub_dir: Sub-directory to group TensorBoard logs. If a sub_dir argument is passed
            then logs are saved in ``/save_dir/version/sub_dir/``. Defaults to ``None`` in which
            logs are saved in ``/save_dir/version/``.
        \**kwargs: Additional arguments used by :class:`SummaryWriter` can be passed as keyword
            arguments in this logger. To automatically flush to disk, `max_queue` sets the size
            of the queue for pending logs before flushing. `flush_secs` determines how many seconds
            elapses before flushing.

    
NAME_HPARAMS_FILE
hparams.yaml
LOGGER_JOIN_CHAR
-
__init__
<function TensorBoardLogger.__init__ at 0x0000025ACE64F160>
root_dir
<property object at 0x0000025ACE673B80>
log_dir
<property object at 0x0000025ACE650040>
save_dir
<property object at 0x0000025ACE650220>
sub_dir
<property object at 0x0000025ACE77DB80>
experiment
<property object at 0x0000025ACE791A90>
log_hyperparams
<function TensorBoardLogger.log_hyperparams at 0x0000025ACEF1D5E0>
log_metrics
<function TensorBoardLogger.log_metrics at 0x0000025ACEF1D700>
log_graph
<function TensorBoardLogger.log_graph at 0x0000025ACEF1D820>
save
<function TensorBoardLogger.save at 0x0000025ACEF1D940>
finalize
<function TensorBoardLogger.finalize at 0x0000025ACEF1DA60>
name
<property object at 0x0000025ACEF0FF40>
version
<property object at 0x0000025ACEF0FF90>
_get_next_version
<function TensorBoardLogger._get_next_version at 0x0000025ACEF1DC10>
_sanitize_params
<staticmethod object at 0x0000025ACE64C760>
__getstate__
<function TensorBoardLogger.__getstate__ at 0x0000025ACEF1DD30>
__abstractmethods__
frozenset()
_abc_impl
<_abc._abc_data object at 0x0000025ACEF1E500>
